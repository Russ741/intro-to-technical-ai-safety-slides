<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title>Language Models</title>
  <style type="text/css">
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" type="text/css" media="screen, projection, print"
    href="https://www.w3.org/Talks/Tools/Slidy2/styles/slidy.css" />
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <script src="https://www.w3.org/Talks/Tools/Slidy2/scripts/slidy.js"
    charset="utf-8" type="text/javascript"></script>
</head>
<body>
<div class="slide titlepage">
  <h1 class="title">Language Models</h1>
</div>
<div id="what-is-a-language-model" class="slide section level1">
<h1>What is a Language Model</h1>
<ul class="incremental">
<li>Abstractly: A machine learning model that works with natural
language text</li>
<li>More concretely: A neural net (or arrangement of neural nets) that
takes in text and spits out either more text or embedding</li>
<li>For a lot of this presentation we’re going to focus in on one use
case: natural language translation</li>
</ul>
</div>
<div id="caveat" class="slide section level1">
<h1>Caveat</h1>
<ul class="incremental">
<li>I’m shakier about some of these concepts</li>
<li>I believe I understand the fundamentals, but I still haven’t
implemented this from scratch in code yet!</li>
<li>We’re going to be stacking a lot of things on top of each other
<ul class="incremental">
<li>It’s totally okay (and expected!) that a lot of this won’t stick
(didn’t for me the first time!)</li>
<li>Think of it as “pre-soaking” your brain so that you can consume more
material about this if you’re interested further</li>
<li>We’ll mainly be focusing on “attention” today</li>
</ul></li>
</ul>
</div>
<div id="brief-recap-of-neural-nets" class="slide section level1">
<h1>Brief recap of neural nets</h1>
<div class="figure">
<img src="./neural_net.svg" alt="" />
<p class="caption">“Neural net visualization”</p>
</div>
</div>
<div id="brief-recap-of-neural-nets-more" class="slide section level1">
<h1>Brief recap of neural nets (more)</h1>
<ul class="incremental">
<li>Individually simple neurons connected via layers</li>
<li>Weights and biases are changed in training
<ul class="incremental">
<li>Number of neurons and layer structures do not change in
training</li>
</ul></li>
<li>Theoretically universal
<ul class="incremental">
<li>In practice often learns spurious relationships without more
safeguards</li>
<li>Architectures provide these safeguards and are therefore subtractive
not additive</li>
</ul></li>
<li>Calculating with weights and biases can be rewritten as matrix
multiplication and addition
<ul class="incremental">
<li>Every layer-to-layer connection of weights can be interpreted as a
matrix of size n x m
<ul class="incremental">
<li>n is the size of the previous layer and m is the size of the next
layer</li>
<li>Entries in matrices are connection weights between two neurons</li>
<li>Passing the outputs of one layer as the inputs to the next is
multiplication of those inputs by the matrix</li>
</ul></li>
<li>Every set of biases of a layer of neurons can be interpeted as a
matrix (with a single column)
<ul class="incremental">
<li>Each neuron in the layer has one bias entry in the matrix</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="questions-about-basic-neural-nets"
class="slide section level1">
<h1>Questions about basic neural nets?</h1>
<ul class="incremental">
<li>Pause for questions (we’re going to keep stacking matrices!)</li>
</ul>
</div>
<div id="the-problem-of-memory-and-reference"
class="slide section level1">
<h1>The Problem of Memory and Reference</h1>
<ul class="incremental">
<li>“The car was driving too quickly through the field. <em>It</em>
crashed into a tree.”</li>
<li>“La voiture roulait trop vite dans le champ. <em>Elle</em> s’est
écrasé contre un arbre.”</li>
<li>How do we correctly translate <em>it</em> (should be “elle” not
“il”)?
<ul class="incremental">
<li>How can the model learn that “it” refers to “car” not “field?”</li>
</ul></li>
</ul>
</div>
<div id="vanilla-neural-nets" class="slide section level1">
<h1>Vanilla Neural Nets</h1>
<ul class="incremental">
<li>In theory a vanilla neural net should be able to learn how to do
this
<ul class="incremental">
<li>After all neural nets are universal</li>
</ul></li>
<li>In practice it’s almost impossible to get it to work
<ul class="incremental">
<li>Almost always learns spurious relationships</li>
<li>We need to be able to “coax” it, i.e. add a variety of
guardrails</li>
<li>Hence new architectures combining neural nets in predefined ways
that cannot be modified by training</li>
</ul></li>
</ul>
</div>
<div id="historical-approaches" class="slide section level1">
<h1>Historical approaches</h1>
<ul class="incremental">
<li>LSTM (long short-term memory)</li>
<li>RNN (recurrent neural nets)</li>
<li>No longer as popular as <em>transformers</em>
<ul class="incremental">
<li>So I haven’t studied them much and can tell you very little about
them…</li>
</ul></li>
</ul>
</div>
<div id="transformers" class="slide section level1">
<h1>Transformers</h1>
<ul class="incremental">
<li>“Attention is all you need” (2017)
<ul class="incremental">
<li>Previous approaches had tried to combine attention with other
mechanisms</li>
<li>This discards everything except attention</li>
</ul></li>
</ul>
</div>
<div id="overview-of-a-transformer" class="slide section level1">
<h1>Overview of a transformer</h1>
<ul class="incremental">
<li>Encoder-decoder architecture (not transformer specific)</li>
<li>Text encoding (not transformer specific)</li>
<li>Attention (not transformer specific, but only using attention
without other mechanisms is!)</li>
</ul>
<div class="figure">
<img src="./transformer_arch.webp" alt="" />
<p class="caption">“Transformers Architecture”</p>
</div>
</div>
<div id="encoder-decoder" class="slide section level1">
<h1>Encoder + decoder</h1>
<ul class="incremental">
<li>Have one neural net (or set of nets) that outputs some abstract
representation of text</li>
<li>Have another neural net (or set of nets) decode that abstract
representation back to natural language</li>
</ul>
</div>
<div id="attention" class="slide section level1">
<h1>Attention</h1>
<ul class="incremental">
<li>Inspired by the idea of human attention</li>
<li>Trying to prod the model towards learning a notion of
“attention”</li>
<li>When translating a single word you’re thinking about others things
in “context”</li>
</ul>
</div>
<div id="attention-as-a-db-query" class="slide section level1">
<h1>Attention as a DB query</h1>
<ul class="incremental">
<li>I have a database with keys and values. Keys are chosen to play
nicer with queries, values are what I actually return in the data.</li>
<li><code>[("Alice", "some data about Alice"), ("Bob", "some data about Bob")]</code></li>
<li>Query “Get me data about keys/names that start with ‘A’”</li>
<li>Match query against key</li>
</ul>
</div>
<div id="abstract-steps-of-db-query" class="slide section level1">
<h1>Abstract steps of DB query</h1>
<ul class="incremental">
<li>Split data into keys and values</li>
<li>Generate a query</li>
<li>Compare queries with keys</li>
<li>Use comparison to select which values to return</li>
</ul>
</div>
<div id="what-about-a-fuzzy-db-query" class="slide section level1">
<h1>What about a “fuzzy” DB query?</h1>
<ul class="incremental">
<li>Split data into keys and values</li>
<li>Generate a query</li>
<li>Instead of binary comparison, yes/no, do a fuzzy match score between
0 and 1</li>
<li>Multiply each value by the fuzzy match and combine them all together
to return a “fuzzy” match</li>
<li>This degenerates to a normal DB query if we just constrain the
fuzziness to either 0 or 1</li>
</ul>
</div>
<div id="equivalents-in-attention" class="slide section level1">
<h1>Equivalents in attention</h1>
<ul class="incremental">
<li>Generate a key and value vector from a given word</li>
<li>Generate a query vector from the word</li>
<li>Dot product the query vector against the key vector to generate
weights</li>
<li>Multiply each value vector by the weights</li>
</ul>
</div>
<div id="generating-the-key-value-and-query-vectors"
class="slide section level1">
<h1>Generating the key, value, and query vectors</h1>
<ul class="incremental">
<li>We have matrices for each key, value, and query
<ul class="incremental">
<li><span class="math inline">\(W_k\)</span>, <span
class="math inline">\(W_v\)</span>, and <span
class="math inline">\(W_q\)</span></li>
</ul></li>
<li>These matrix values are learned during training</li>
</ul>
</div>
<div id="working-through-a-specific-example"
class="slide section level1">
<h1>Working through a specific example</h1>
<ul class="incremental">
<li>“The car was driving too quickly through the field. <em>It</em>
crashed into a tree.”</li>
<li>Look at a single given word “it”, which has some vector form after
embedding</li>
<li>Multiply <em>every word</em>’s embedding by <span
class="math inline">\(W_k\)</span> to generate key vectors for all of
them</li>
<li>Multiply <em>every word</em>’s embedding by <span
class="math inline">\(W_v\)</span> to generate value vectors for all of
them</li>
<li>Multiply “it” embedding by <span class="math inline">\(W_q\)</span>
to generate a single query vector</li>
<li>Dot product query vector against every key vector to get weights
against every value</li>
<li>Multiply every value by weight and add them altogether to the final
attention result</li>
<li><img src="attention_example.png" title="fig:"
alt="Attention weight visualization" /></li>
</ul>
</div>
<div id="why-multi-head-attention" class="slide section level1">
<h1>Why Multi-Head Attention?</h1>
<ul class="incremental">
<li>Empirical tuning (like so much of ML!)</li>
<li>The entirety of the reasoning in the original paper: “We found it
beneficial” <a href="https://arxiv.org/pdf/1706.03762.pdf">the original
paper</a></li>
</ul>
</div>
<div id="stacking-attention-on-top-of-attention"
class="slide section level1">
<h1>Stacking attention on top of attention</h1>
<ul class="incremental">
<li>Keep stacking attention matrices on top of rounds of merging
multiple attention streams</li>
<li>Query, key, value intuition kind of falls apart
<ul class="incremental">
<li>What is attention “<em>really</em>”?</li>
<li>At the end of the day a particular set of guardrails on neural nets
that seems to make models good at language</li>
<li>Again no reason in theory why a sufficiently large single neural net
couldn’t subsume the idea of attention
<ul class="incremental">
<li>It just doesn’t happen in practice</li>
<li>Too many spurious relationships</li>
<li>The guardrails provided by attention cut down on spurious
relationships (i.e. subtractive, not additive new capabilities)</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="position-matters" class="slide section level1">
<h1>Position matters!</h1>
<ul class="incremental">
<li>Notice that nothing about attention</li>
</ul>
</div>
<div id="following-the-life-of-a-input-through-a-transformer"
class="slide section level1">
<h1>Following the life of a input through a transformer</h1>
<ul class="incremental">
<li>Input: “I like dogs.”</li>
<li>Tokenization: <code>[2349, 9, 23]</code></li>
<li>After embedding + positional encoding:
<code>[[0.2, ..., 0.9], [0.1, ..., ]]</code></li>
</ul>
</div>
<div id="transformers-in-the-wild" class="slide section level1">
<h1>Transformers in the wild</h1>
<ul class="incremental">
<li>Many models only use one half of the transformer</li>
<li>E.g. BERT only uses the encoder half of the transformer
<ul class="incremental">
<li>So BERT ultimately ends with a set of encodings, <em>not</em>
natural language output!</li>
</ul></li>
<li>GPT uses only the decoder half of the transformer (which is a input
= text, output = input + more stuff model)</li>
</ul>
</div>
</body>
</html>
